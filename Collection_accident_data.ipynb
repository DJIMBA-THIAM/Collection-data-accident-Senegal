{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # pour le database\n",
    "import requests    # pour envoyer une requete \n",
    "from bs4 import BeautifulSoup   # pour la collection\n",
    "from text_to_num import alpha2digit  # pour remplacer les nombres ecrivent en lettres en chiffre \n",
    "import spacy # pour le traitement de texte en decoupant le texte en token \n",
    "import re  # pour supprimer les espaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mbadiane', 'Koussanar', 'Sakately', 'Kahène', 'Ngoye', 'Gniby', 'Patar', 'Ndiédieng', 'Koussanar', 'Bona', 'Niaguis', 'Bandègne Ouolof', 'Camaracounda', 'Sagatta Fall', 'Médina Sabakh', 'Khombole', 'Gade Escale', 'Sagatta Dioloff', 'Guédé Village', 'Keur Madiabel', 'Sibassor', 'Nguer Malal', 'Darou Marnane', 'Diouloulou', 'Fafacourou', 'Madina Foulbé', 'Kanel', 'Kanène Ndiob', 'Dodji', 'Gare', 'Diattacounda', 'Séssène', 'Tenghory', 'Gainte Pathé', 'Sansamba', 'Sénégal', 'Salikégné', 'Thiel', 'Khossanto', 'Thilmakha', 'Syer', 'Louga', 'Ndindy', 'Tattaguine', 'Coki', 'Gaé', 'Tankanto Escale', 'Gamadji Sarré', 'Kaolack', 'Malem Hodar', 'Notto', 'Gabou', 'Dioulacolon', 'Dodji', 'Bandafassi', 'Niakhène', 'Wack Ngouna', 'Kafountine', 'Yop', 'Thiolly', 'Niagha', 'Wack Ngouna', 'Paoscoto', 'Diaoulé', 'Bassoul', 'Sam Yabal', 'Keur Moussa', 'Gossas', 'Rao', 'Djilor', 'Pambal', 'Ngoye', 'Mpal', 'Thieppe', 'Mboss', 'Sindian', 'Ourossogui', 'Koumpentoum', 'Darou Mousty', 'Aouré', 'Nioro Allassane Tall', 'Saré Bidji', 'Touba Mérina', 'Réfane', 'Diendé', 'Niamone', 'Ndiayène Sirah', 'Sakar', 'Bonconto', 'Kartiack', 'Pikine', 'Loudia Ouoloff', 'Kébémer', 'Orkadiéré', 'Djirnda', 'Bani Israèl', 'Colobane', 'Communautés rurales', 'Niomré', 'Keur Samba Guèye', 'Djanké Souf', 'Djemberring', 'Taïf', 'Dagana', 'Koulor', 'Kab Gaye', 'Kelle Guèye', 'Lougré', 'Salémata', 'Pété', 'Thiaroye', 'Keur Maba Diakhou', 'Ndiayène Pendao', 'Touba Toul', 'Dinguiraye', 'Médina Dakhar', 'Méouane', 'Birkelane', 'Podor', 'Dabia', 'Parcelles Assainies', 'Diokoul Mbelbouck', 'Netté Boulou', 'Salémata', 'Orkadiéré', 'Thillé Boubacar', 'Pata', 'Yang Yang', 'Mboro', 'Djignaki', 'Keur Momar Sarr', 'Ndiaffate', 'Malem Hodar', 'Matam', 'Richard Toll', 'Ida Mouride', 'Sakal', 'Diarrère', 'Dabo', 'Darou Salam Typ', 'Ngoudiane', 'Guediawaye', 'Dya', 'Prokhane', 'Médina Dakhar', 'Kéniaba', 'Ndondol', 'Thiomby', 'Mbour', 'Boulal', 'Ngayokhème', 'Léona', 'Bounkiling', 'Makacoulibantang', 'Ngandiouf', 'Mbane', 'Niakhar', 'Mbadakhoune', 'Tambacounda', 'Némataba', 'Dialacoto', 'Linguère', 'Enampor', 'Bounkiling', 'Ziguinchor', 'Darou Minam 2', 'Mampatim', 'Fandène', 'Mlomp', 'Oréfondé', 'Diokoul Diawrigne', 'Thiénaba', 'Nguène', 'Kounkané', 'Barkedji', 'Séssène', 'Bambali', 'Bokiladji', 'Kaffrine', 'Ndioum', 'Ross', 'Ndiob', 'Sindia', 'Sadio', 'Mboula', 'Bignona', 'Fimela', 'Santhiaba Manjacque', 'Sindia', 'Suelle', 'Sinthiou Bamambé', 'Lambaye', 'Dougue', 'Golléré', 'Thilogne', 'Diakhao', 'Ranérou', 'Béthio', 'Kahone', 'Ouonck', 'Mboumba', 'Gandon', 'Gassane', 'Fissel', 'Benet', 'Médina Baffé', 'Oussouye', 'Gagnick', 'Bandafassi', 'Oulampane', 'Boulel', 'Géoul', 'Dangalma', 'Sakal', 'Latmingué', 'Communes', 'Nguékhokh', 'Bokidiawé', 'Bakel', 'Ranérou', 'Médinatoul Salam II', 'Loro', 'Sinthiou Bamambé', 'Saraya', 'Sébikhotane', 'Niassia', 'Aéré', 'Fadiouth', 'Almadies', 'Thiénaba', 'Mbeuleukhé', 'Loul Séssène', 'Toubacouta', 'Touba Mboul', 'Mbacke', 'Gandiaye', 'Barkédji', 'Mbar', 'Ndiago', 'Coumbacara', 'Thiargny', 'Diamniadio', 'Diégoune', 'Karantamba', 'Koul', 'Ngathe Naoudé', 'Kahi', 'Colobane', 'Médina Yoro Foulah', 'Bala', 'Ndiédieng', 'Ribot Escale', 'Médina El Hadj', 'Diattacounda', 'Dendey Gouyegui', 'Bonconto', 'Ndiebel', 'Koumpentoum', 'Samine Escale', 'Oukout', 'Médina Gounass', 'Malicounda', 'Mbéllacadio', 'Missirah', 'Galoya Toucouleur', 'Marsassoum', 'Ndande', 'Tassette', 'Ndoulo', 'Palmarin Facao', 'Médina Sabakh', 'Keur Moussa', 'Saldé', 'Dankh Sène', 'Taïf', 'Mbadakhoune', 'Toubacouta', 'Sarr', 'Sindian', 'Kael', 'Tenghory', 'Diouloulou', 'Touba Fall', 'Darou Mousty', 'Diourbel', 'Tanaff', 'Dakar', 'Niaguis', 'Goudiry', 'Diouroup', 'Sandiara', 'Dagoudane', 'Mbédiène', 'Thiamène Cayor', 'Djirédji', 'Louis', 'Pékesse', 'Madina', 'Dabo', 'Semmé', 'Tivaouane', 'Bambey', 'Sinthiou Malèm', 'Niakhar', 'Lao', 'Bagadadji', 'Maka', 'Thiès', 'Plateau', 'Ndoga Boubacar', 'Ndiéné Lagane', 'Koungheul', 'Déali', 'Boutoupa', 'Tattaguine', 'Pakour', 'Linkéring', 'Ndoulo', 'Wourour Sidy', 'Vélingara', 'Nbayène', 'Vélingara', 'Sagatta Dioloff', 'Madina', 'Ouadiour', 'Labgar', 'Thiaré', 'Keur Samba Kane', 'Médina Yoy Foulah', 'Arrondissements', 'Agnam', 'Keur Socé', 'Diofor', 'Sangalkam', 'Missirah Sirimana', 'Passy', 'Nguéniène', 'Tessékéré Forage', 'Rosso', 'Saint', 'Essyl', 'Fanaye', 'Ballou', 'Mangagoulack', 'Chérif Lo', 'Fatick', 'Niodior', 'Thionck', 'Ouadiour', 'Simbandi Brassou', 'Keur Momar Sarr', 'Diawara', 'Missirah', 'Gandé', 'Mont Rolland', 'Waoundé', 'Ngogom', 'Ndoffane', 'Gamadji Sarré', 'Koumbal', 'Sangalkam', 'Sagatta', 'Ndiognick', 'Paroumba', 'Tanaff', 'Sadatou', 'Thiamène Djolof', 'Moudéry', 'Fissel', 'Kandia', 'Ndioumane Taiba', 'Kamb', 'Yop', 'Saraya', 'Thiékène', 'Joal', 'Nganda', 'Dianah Malari', 'Notto Gouye', 'Maka', 'Ndande', 'Kalibantang', 'Sinthiang Koundara', 'Saré Coly Salé', 'Kouthiaba Wolof', 'Ogo', 'Dionewar', 'Cabrousse', 'Ourour', 'Ogo', 'Bamba Thialène', 'Ballingore', 'Kounkané', 'Foundiougne', 'Patar Lia', 'Goudomp', 'Pire Gourèye', 'Lambaye', 'Djibanar', 'Ouarkhokh', 'Civol', 'Bargny', 'Mabo', 'Tocky', 'Belé', 'Tomboronkoto', 'Ndiaganiao', 'Djibidione', 'Kayemor', 'Djilor', 'Touba Mosquée', 'Ndiamacouta', 'Mbediène', 'Keur Ngalgou', 'Coubalan', 'Mbane', 'Mlomp', 'Sédhiou', 'Malem Niani', 'Taïba Niassène', 'Diaroumé', 'Tendouck', 'Taiba Moutoupha', 'Ndame', 'Kédougou', 'Gawane', 'Adéane', 'Ndindy', 'Ndorma', 'Diendé', 'Saly Escale', 'Nguidillé', 'Nabbadji Civol', 'Djibabouya', 'Taïba Ndiaye', 'Civol', 'Baba Garage', 'Méckhé', 'Grand Dakar', 'Ngabou Dalla', 'Dimboli', 'Notto', 'Dahra', 'Niassia', 'Ngohé', 'Ouassadou', 'Pout', 'Sokone', 'Gathiary', 'Rufisque', 'Gainthe Kaye', 'Djibabouya', 'Ndioum Ngainthe', 'Dakar', 'Baba Garage', 'Kothiary', 'Patar', 'Nganda', 'Lour Escale', 'Méouane', 'Keur Maka', 'Coki', 'Fimela', 'Nioro du rip', 'Nghoye', 'Kolda', 'Keur Saloum Diané', 'Kidira', 'Bijini', 'Goudiry', 'Ndoyenne', 'Kael', 'Sinthiou Fissa', 'Guinguinéo', 'Thiadiaye', 'Birkelane', 'Fongolembi', 'Diender Geudj', 'Diama', 'Yène', 'Touré Mbonde', 'Diakhao', 'Ngayène', 'Ndiagne', 'Niayes', 'Niakhène', 'Thiakar', 'Paoscoto', 'Makacoulibantang', 'Fongolembi', 'Pété Ouarack', 'Kathiotte', 'Diossong', 'Dioulacolon', 'Ndramé Escale', 'Ndiatbé', 'Djilasse', 'Dodel', 'Rufisque', 'Niaro', 'Guédiawaye']\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Cette partie permet de recueillir les noms des communes, arrondissements et villagees \n",
    "du Senegal dans une liste nommee Senegal\"\"\"\n",
    "\n",
    "url_ = \"https://www.planete-senegal.com/senegal/decoupage_administratif_senegal.php\"\n",
    "\n",
    "reponse = requests.get(url_)\n",
    "\n",
    "if reponse.status_code == 200:\n",
    "    #recuperer le code html\n",
    "    html = reponse.text\n",
    "    \n",
    "    communes, arrondissements, villages = [], [], []\n",
    "    # scraper\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    # Scraper tous les communes, les arrondissements et les villages du Senegal\n",
    "    all_content_page = soup.find(\"table\", width = \"100%\", border = \"1\")\n",
    "    all_communes = all_content_page.find_all(\"td\", width = \"20%\")\n",
    "    all_arrondissement = all_content_page.find_all(\"td\", width = \"26%\")\n",
    "    all_villages = all_content_page.find_all(\"td\", width = \"39%\")\n",
    "    \n",
    "    # Les communes\n",
    "    for commune in all_communes:\n",
    "        communes.append(commune.text.strip().replace(\"\\r\\n\", \"\"))\n",
    "        \n",
    "    # Les arrondissements\n",
    "    for arrondissement in all_arrondissement:\n",
    "        arrondissements.append(arrondissement.text.strip().replace(\"\\r\\n\", \"\"))\n",
    "        \n",
    "    # Les villages\n",
    "    for village in all_villages:\n",
    "        villages.append(village.text.strip().replace(\"\\r\\n\", \"\"))\n",
    "        \n",
    "    # Remplacer les espaces multiples par un seul espace\n",
    "    resultat_communes_propres = [re.sub(r'\\s+', ' ', commune) for commune in communes]\n",
    "    resultat_arrondissement_propres = [re.sub(r'\\s+', ' ', arrondissement) for arrondissement in arrondissements]\n",
    "    resultat_villages_propres = [re.sub(r'\\s+', ' ', village) for village in villages]\n",
    "    \n",
    "    \n",
    "    # Separer tous les communes en supprimant le caractere \"-\"\n",
    "    communes_propres = []\n",
    "    for com in resultat_communes_propres:\n",
    "        if com != \"Rosso-Sénégal\":\n",
    "            communes_propres.extend(com.strip().split(\"-\"))\n",
    "            \n",
    "           \n",
    "    # Separer tous les arrondissements en supprimant le caractere \"-\"\n",
    "    arrondissements_propres = []\n",
    "    for arron in resultat_arrondissement_propres:\n",
    "        if arron not in [\"Dakar-Plateau\", \"Ross-Béthio\", \"Cas-cas\"]:\n",
    "            arrondissements_propres.extend(arron.strip().split(\"-\"))\n",
    "            \n",
    "            \n",
    "    # Separer tous les villages en supprimant le caractere \"-\"\n",
    "    villages_propres = []\n",
    "    for villa in resultat_villages_propres:\n",
    "        villages_propres.extend(villa.strip().split(\"-\"))\n",
    "    \n",
    "    # suppresion des cases vides    \n",
    "    villages_propres = list(filter(None, villages_propres))\n",
    "     \n",
    "     \n",
    "    # Regroupement communes, les arrondissements et les villages du Senegal\n",
    "    senegal = set(communes_propres) | set(arrondissements_propres) | set(villages_propres)\n",
    "    senegal = list(senegal)\n",
    "    \n",
    "    # suppresion des espaces vides\n",
    "    senegal = [n.strip() for n in senegal]\n",
    "    \n",
    "    # Enrichir la liste senegal\n",
    "    senegal.extend((\"Niaro\", \"Guédiawaye\"))\n",
    "    \n",
    "    print(senegal)\n",
    "    \n",
    "else:\n",
    "    print(\"ERREUR:\", reponse.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle spaCy\n",
    "nlp = spacy.load(\"fr_core_news_md\")\n",
    "\n",
    "# Constantes\n",
    "URL = \"https://www.senenews.com/tag/accident\"\n",
    "\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:126.0) Gecko/20100101 Firefox/126.0\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_html(url, headers):\n",
    "    \"\"\"Recuper le contenu HTML de l'url.\"\"\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        print(\"ERREUR:\", response.status_code)\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html_to_file(html, filename):\n",
    "    \"\"\"Sauvarge le code HTML dans un fichier.\"\"\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(html):\n",
    "    \"\"\"Parse contenu HTML en utilisant BeautifulSoup.\"\"\"\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    return soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_gravity(nombre_morts):\n",
    "   \"\"\"Determine la gravite de l'accident.\"\"\"\n",
    "   if nombre_morts is not None and nombre_morts > 0:\n",
    "       return \"grave\"\n",
    "   else:\n",
    "      return \"non grave\"     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information(doc):\n",
    "    \"\"\"Extraction des informations sur les textes.\"\"\"\n",
    "    lieu_accident = None\n",
    "    nombre_morts = 0\n",
    "    nombre_blesses = 0\n",
    "    \n",
    "    def extract_numbers(token):\n",
    "        prev_token = token.nbor(-1) \n",
    "        if prev_token.like_num:\n",
    "            return 1 if prev_token.text.lower() == \"un\" else int(prev_token.text)\n",
    "        return 0\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text in senegal:\n",
    "            lieu_accident = token.text\n",
    "        elif \"mort\" in token.text.lower():\n",
    "            nombre_morts = extract_numbers(token)\n",
    "        elif \"blessé\" in token.text.lower():\n",
    "            nombre_blesses = extract_numbers(token)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return lieu_accident, nombre_morts, nombre_blesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour récupérer la date à partir du lien de l'article\n",
    "def get_article_date(article_url):\n",
    "    \"\"\" Recupere la date à partir du lien\"\"\"\n",
    "    response = requests.get(article_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Trouver la balise <span class=\"date updated\">\n",
    "    date_span = soup.find('span', class_='date updated')\n",
    "    \n",
    "    if date_span:\n",
    "        return date_span.text.strip()  # Retourner le texte contenu dans la balise\n",
    "    else:\n",
    "        return None  # Retourner None si la balise n'est pas trouvée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour récupérer les titres d'articles contenant le mot \"accident\" et leur date associée\n",
    "def get_accident_articles_with_dates(soup):\n",
    "   \n",
    "    articles_with_dates = []\n",
    "\n",
    "    # Trouver tous les liens des articles\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        article_url = link['href']\n",
    "        \n",
    "        # Vérifier si le titre de l'article contient le mot \"accident\"\n",
    "        if 'accident' in link.text.lower():\n",
    "            # Trouver la date associée à cet article\n",
    "            date = get_article_date(article_url)\n",
    "            if date:\n",
    "                articles_with_dates.append({'title': link.text.strip(), 'date': date})\n",
    "                \n",
    "        # Ajouter un délai entre chaque requête\n",
    "        #time.sleep(2)  # Attendre 2 secondes entre les requêtes            \n",
    "\n",
    "    return articles_with_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour supprimer les heures au niveau de la date\n",
    "def remove_time(date_str):\n",
    "    \"\"\"Remove time from a datetime string.\"\"\"\n",
    "    if ' à ' in date_str:\n",
    "        return date_str.split(' à ')[0]\n",
    "    return date_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############  #################################################\n",
    "\n",
    "def extract_data(soup):\n",
    "    \"\"\"Extract relevant data from parsed HTML.\"\"\"\n",
    "    data = pd.DataFrame(columns=[\"Jour\", \"Lieu\", \"Nombre_victimes\", \"Nombre_blesses\", \"Nombre_morts\", \"Gravite\"])\n",
    "    \n",
    "     # Intégrer la récupération des titres d'articles avec leur date associée\n",
    "    accident_articles_with_dates = get_accident_articles_with_dates(soup) \n",
    "    \n",
    "    for article in accident_articles_with_dates:\n",
    "        # Extraire les informations pertinentes pour chaque article\n",
    "        texte = article['title']\n",
    "        date = remove_time(article['date'])\n",
    "        text = alpha2digit(texte, \"fr\")\n",
    "        doc = nlp(text)\n",
    "        lieu_accident, nombre_morts, nombre_blesses = extract_information(doc)\n",
    "        gravite_accident = determine_gravity(nombre_morts)\n",
    "        \n",
    "        # Ajouter les informations extraites dans le dataframe\n",
    "        new_row = pd.DataFrame([{\n",
    "            \"Jour\" : date,\n",
    "            \"Lieu\": lieu_accident,\n",
    "            \"Nombre_victimes\": nombre_morts + nombre_blesses,\n",
    "            \"Nombre_blesses\": nombre_blesses,\n",
    "            \"Nombre_morts\": nombre_morts,\n",
    "            \"Gravite\": gravite_accident\n",
    "        }])\n",
    "        data = pd.concat([data, new_row], ignore_index=True)\n",
    "    \n",
    "    # Remplacer les valeurs None par \"NA\" dans la colonne \"Lieu\"\n",
    "    data[\"Lieu\"].fillna(\"NA\", inplace=True)\n",
    "    \n",
    "    # Réindexer pour commencer à 1\n",
    "    data.index = range(1, len(data) + 1) \n",
    "    \n",
    "            \n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# FONCTION PRINCIPALE ###################################\n",
    "\n",
    "def main():\n",
    "    html = fetch_html(URL, HEADERS)  # Entrer l'url et l'entete\n",
    "    \n",
    "    if html:\n",
    "        save_html_to_file(html, \"Accident-Senenews.html\")\n",
    "        soup = parse_html(html) # parse le contenu html\n",
    "        data = extract_data(soup) # extraction des donnees \n",
    "        \n",
    "        print(data) # Affichage de la base de donnees\n",
    "        \n",
    "        # Export data \n",
    "        #data.to_excel(\"C:/Users/Mouha/OneDrive/Desktop/MEMOIRE/Code_memoire_mouhamadou_djimba_thiam/scraping_senenew_memoire/data_accident_senegal_new.xlsx\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
